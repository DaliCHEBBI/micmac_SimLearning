\chapter{Pushbroom sensors}
\label{Chap:PushBroom}


%-----------------------------------------------------------------------
%-----------------------------------------------------------------------
%-----------------------------------------------------------------------


%  9 0157  0002 2184 5
%  90157000221845
\section{Notice to the reader}

This chapter present how pushbroom sensors are handled in {\tt MMVII}.
It is written before a programmation session scheduled in mars $2024$
as a support to this session;
it will be probably significantly modified after the session and is different
from the other chapter in two points :

\begin{itemize}
	\item  the  chapter mixes theoreticall aspects with practicall aspects
		of implementation in micmac (some reorganization will probably occur later);
	\item  the theory and organisation are written (at least the first drafts)
               before the actual implementation;
\end{itemize}


%-----------------------------------------------------------------------
%-----------------------------------------------------------------------
%-----------------------------------------------------------------------

\section{Physicall and mathematical modelisation}

%-----------------------------------------------------------------------
\subsection{Physicall model}

\begin{figure}
\centering
\includegraphics[width=6cm]{Methods/Images/PushB1.jpg}\caption{Notation for pushbroom sensor}
        \label{fig:PushB1}
\end{figure}


A pushbroom sensor is made a monodimensional line sensor which has deplacement during the time.
This is the deplacement that create the second dimension. We suppose in the following  that in the
formed  image the coordinte $j$ correspond to a line og the monodimensionnal sensor while the coordinate
$i$ correspond to the "time". We note as in figure~\ref{fig:PushB1}:

\begin{itemize}
	\item  $C(t)=C(i)$ the position of the sensor at time $t$;
	\item  $R(t)=R(i)=[\vec{I},\vec{J},\vec{K}]$ the orientation of the sensor at time $t$;
	\item  $\vec{u}(j)$ the direction of bundle in the repair of the sensor;
	\item  $\vec{U}(i,j) = R(i)\vec{u}(j)$ the direction of bundle in the global repair;
	\item  $B(i,j)= (C(i),\vec{U}(i,j))$ the bundle issued of pixel $i,j$;
\end{itemize}

The localisation function is completly caracterized by the mapping $(i,j) \rightarrow B(i,j)$.
By the way, practically we prefer to use the projection $\pi$ that  compute the 
image $i,j$ of given ground point, $\pi : (x,y,z) \rightarrow (i,j)$.  To make
$\pi$ and invertible function we change slightly to $\pi : (x,y,z) \rightarrow (i,j,z)$.
The function "easy" to compute from the previous notation is $\pi^{-1}$,
we have the parametric equation of $B(i,j)(\lambda) = C(i) + \lambda \vec{U}(i,j)$,
and computing $\lambda$  to have the right $z$ we get :

\begin{equation}
	\pi^{-1}(i,j,z) = C(i) + \frac{z-C_z(i)}{U_z(i)} \vec{U}(i,j)
\end{equation}

The localisation is completely caracterised by :

\begin{itemize}
	\item  the functions $C(i)$ and $R(i)$;
	\item  the calibration of the sensor, i.e. the maping $j \rightarrow \vec{u}(j)$;
\end{itemize}

%-----------------------------------------------------------------------

\subsection{Satellite model}

Pushbroom sensor are not $100\%$ reserved to satelitte model, they can be used for example for some
aerial camera (see ADS40 frome Leica).
In this chapter we  focuss on satelitte system, this has two consequences :

\begin{itemize}
    \item we assume that $C(i)$  and $R(i)$  are very smooth functions;
    \item we assume that $C(i)$  is known  "perfectly" and that the innaccuracy
          on the model comes only from $R(i)$, and eventualy from the sensor calibration;  this assumption is generally admited
          by the community, as a justification we can give :
    \begin{itemize}
         \item  position comes from GNSS which has a very high accuracy and robustness without obstruction (say a few centimeters);
         \item  orientation comes for stellar sensor, for a saletlite flying at $600km$ at a resolution of $1m$,
                an accuracy of $1$ pixel requires an angular accuracy of $\frac{1}{600000}$ radian or $\frac{1}{10000}$ degree;
     \end{itemize}
\end{itemize}

%-----------------------------------------------------------------------

\subsection{Satellite error model}

Let $R(i)$ be the initial orientation , and $R'(i)$ be the "real orientation"
we want to estimate by adjsument.
We admit that there exist a rotation $R_\Theta(i)$, very close to identity and
very smooth so that :

\begin{equation}
    R'(i) = R_\Theta(i) R(i)
\end{equation}

Noting $\Theta=(\omega,\phi,\kappa)$ and as  $R_\Theta$ is close to identity we will have :

%
%
%

\begin{equation}
    R_\Theta(i) = 
\begin{bmatrix}
1 &  - \kappa & \phi\\
\kappa & 1 & -\omega\\
-\phi & \omega & 1
\end{bmatrix} 	
\end{equation}


$\Theta(i)$ will be the unknown we want to compute, but for now
we suppose we know it. 
Let $\pi$ be the initial projection, we want to compute the modify
projection $\pi'$.
For the invert projection, it's quite easy, let's note  :

\begin{equation}
    \vec{U'} =  R_\Theta \vec{U}
\end{equation}

Then we have :

\begin{equation}
	\pi'^{-1}(i,j,z) = C(i) + \frac{z-C_z(i)}{U'_z(i)} \vec{U'}(i,j)
\end{equation}


Now for computing $\pi'(P)$ we must compute $q'=(i',j',z)$ such that :

\begin{equation}
        \pi'^{-1}(q') = P
\end{equation}

Considering $\pi'$ as a function of both $q$ and $\Omega$,  we can make a taylor expansion :


\begin{equation}
        \pi'^{-1}(q')
      =      \pi^{-1}(q) 
      +  \frac{\partial \pi^{-1}}{\partial i }  \delta_i
      +  \frac{\partial \pi^{-1}}{\partial j }  \delta_j
\end{equation}
         %+   \frac{\part \pi^{-1}}{\part i} \delta_i

Considering $\pi'$ as a function of both $q$ and $\Omega$,  we can make a taylor expansion :



%-----------------------------------------------------------------------
\section{Vrac}

\begin{itemize}
    \item begin by example with polynomial image
    \item method with some reverse engenering,  $\pi$ and $\pi^{-1}$ being "black box"
\end{itemize}


